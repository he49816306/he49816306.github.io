{"meta":{"title":"Malroy的博客","subtitle":"会当凌绝顶","description":"重庆科技大学 | 计算机科学与技术 | 自然语言处理","author":"Malroy","url":"http://he49816306.github.io","root":"/"},"pages":[{"title":"404","date":"2019-07-19T08:41:10.000Z","updated":"2020-06-17T09:38:04.362Z","comments":true,"path":"404.html","permalink":"http://he49816306.github.io/404.html","excerpt":"","text":""},{"title":"archives","date":"2019-07-19T08:39:20.000Z","updated":"2020-06-17T09:38:04.364Z","comments":true,"path":"archives/index.html","permalink":"http://he49816306.github.io/archives/index.html","excerpt":"","text":""},{"title":"contact","date":"2019-07-26T09:17:02.000Z","updated":"2020-06-18T09:16:51.437Z","comments":true,"path":"contact/index.html","permalink":"http://he49816306.github.io/contact/index.html","excerpt":"","text":"欢迎留言大家有任何问题，都可以在评论区给我留言，或者加 QQ 技术交流群【群号：520520520】。 我很忙啦，如果不是很麻烦的问题就直接在评论区留言啦。 友链交换想要交换友链的小伙伴，欢迎在评论区留言，留言格式： 名称：你的博客名称 地址：你的博客地址 简介：一句话简介 头像：你的头像地址"},{"title":"categories","date":"2019-07-19T08:39:20.000Z","updated":"2020-06-17T09:38:04.365Z","comments":true,"path":"categories/index.html","permalink":"http://he49816306.github.io/categories/index.html","excerpt":"","text":""},{"title":"friends","date":"2019-07-19T08:42:10.000Z","updated":"2020-06-18T09:17:06.050Z","comments":true,"path":"friends/index.html","permalink":"http://he49816306.github.io/friends/index.html","excerpt":"","text":"友链交换想要交换友链的小伙伴，欢迎在留言板留言，留言格式： 名称：你的博客名称 地址：你的博客地址 简介：一句话简介 头像：你的头像地址"},{"title":"tags","date":"2019-07-19T08:40:27.000Z","updated":"2020-06-17T09:38:04.366Z","comments":true,"path":"tags/index.html","permalink":"http://he49816306.github.io/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2019-07-19T08:41:10.000Z","updated":"2021-01-07T06:12:11.968Z","comments":true,"path":"about/index.html","permalink":"http://he49816306.github.io/about/index.html","excerpt":"","text":"教育经历 硕士 计算机科学与技术重庆大学2019/06 - 现在 本科 计算机科学与技术 | 软件工程重庆科技大学2014/09 - 2019/06综合排名专业第一 获得荣誉2019 优秀毕业生优秀毕业生（重庆） 一等奖学金奖学金（校级） 企业荣誉项目组特别突出员工 2018 一等奖学金奖学金（校级） 团体一等奖中国高校计算机大赛-团体程序设计天梯赛 高校一等奖中国高校计算机大赛-团体程序设计天梯赛 2017 荣誉证书科技创新优秀学生（校级） 荣誉证书自立自强优秀学生（校级） 铜牌大学生微信小程序大赛（第一届） 一等奖学金奖学金（校级） 2016 国家奖学金奖学金（国家级） 铜牌大学生数学建模大赛（重庆） 联系方式 电子邮箱62614929@qq.com 地址重庆市沙坪坝 QQ 技术交流群520520520"}],"posts":[{"title":"Metrics 设计的最佳实践","slug":"metric-named","date":"2023-03-14T07:17:46.000Z","updated":"2023-03-30T05:34:50.525Z","comments":true,"path":"2023/03/14/metric-named/","link":"","permalink":"http://he49816306.github.io/2023/03/14/metric-named/","excerpt":"","text":"Metrics 设计的最佳实践1 如何确定需要测量的对象在具体设计 Metrics 之前，首先需要明确需要测量的对象。需要测量的对象应该依据具体的问题背景、需求和需监控的系统本身来确定。 思路1：从需求出发Google 针对大量分布式监控的经验总结出四个监控的黄金指标，这四个指标对于一般性的监控测量对象都具有较好的参考意义。这四个指标分别为： 延迟：服务请求的时间。 通讯量：监控当前系统的流量，用于衡量服务的容量需求。 错误：监控当前系统所有发生的错误请求，衡量当前系统错误发生的速率。 饱和度：衡量当前服务的饱和度。主要强调最能影响服务状态的受限制的资源。例如，如果系统主要受内存影响，那就主要关注系统的内存状态。 我认为，以上四种指标，其实是为了满足四个监控需求： 反映用户体验，衡量系统核心性能。如：在线系统的时延，作业计算系统的作业完成时间等。 反映系统的服务量。如：请求数，发出和接收的网络包大小等。 帮助发现和定位故障和问题。如：错误计数、调用失败率等。 反映系统的饱和度和负载。如：系统占用的内存、作业队列的长度等。 除了以上常规需求，还可根据具体的问题场景，为了排除和发现以前出现过或可能出现的问题，确定相应的测量对象。比如，系统需要经常调用的一个库的接口可能耗时较长，或偶有失败，可制定 Metrics 以测量这个接口的时延和失败数。 思路2：从需监控的系统出发另一方面，为了满足相应的需求，不同系统需要观测的测量对象也是不同的。在 官方文档 的最佳实践中，将需要监控的应用分为了三类： 线上服务系统（Online-serving systems）：需对请求做即时的响应，请求发起者会等待响应。如 web 服务器。 线下计算系统（Offline processing）：请求发起者不会等待响应，请求的作业通常会耗时较长。如批处理计算框架 Spark 等。 批处理作业（Batch jobs）：这类应用通常为一次性的，不会一直运行，运行完成后便会结束运行。如数据分析的 MapReduce 作业。 对于每一类应用其通常情况下测量的对象是不太一样的。其总结如下： 线上服务系统：主要有请求、出错的数量，请求的时延等。 线下计算系统：最后开始处理作业的时间，目前正在处理作业的数量，发出了多少 items， 作业队列的长度等。 批处理作业：最后成功执行的时刻，每个主要 stage 的执行时间，总的耗时，处理的记录数量等。 除了系统本身，有时还需监控子系统： 使用的库（Libraries）: 调用次数，成功数，出错数，调用的时延。 日志（Logging）：计数每一条写入的日志，从而可找到每条日志发生的频率和时间。 Failures: 错误计数。 线程池：排队的请求数，正在使用的线程数，总线程数，耗时，正在处理的任务数等。 缓存：请求数，命中数，总时延等。 … 最后的测量对象的确定应结合以上两点思路确定。 2 如何选用 Vector选用 Vec 的原则： 数据类型类似但资源类型、收集地点等不同 Vec 内数据单位统一 例子： 不同资源对象的请求延迟 不同地域服务器的请求延迟 不同 http 请求错误的计数 … 此外，官方文档 中建议，对于一个资源对象的不同操作，如 Read/Write、Send/Receive， 应采用不同的 Metric 去记录，而不要放在一个 Metric 里。原因是监控时一般不会对这两者做聚合，而是分别去观测。 不过对于 request 的测量，通常是以 Label 做区分不同的 action。 3 如何确定 Label根据2，常见 Label 的选择有： resource region type … 确定 Label 的一个重要原则是：同一维度 Label 的数据是可平均和可加和的，也即单位要统一。如风扇的风速和电压就不能放在一个 Label 里。 此外，不建议下列做法： my_metric{label=a} 1 my_metric{label=b} 6 my_metric{label=total} 7 即在 Label 中同时统计了分和总的数据，建议采用 PromQL 在服务器端聚合得到总和的结果。或者用另外的 Metric 去测量总的数据。 4 如何命名 Metrics 和 Label好的命名能够见名知义，因此命名也是良好设计的一环。 Metric 的命名： 需要符合 pattern: (a-zA-Z:)(a-zA-Z0-9:)* 应该包含一个单词作为前缀，表明这个 Metric 所属的域。如： prometheus_notifications_total process_cpu_seconds_total ipamd_request_latency 应该包含一个单位的单位作为后缀，表明这个 Metric 的单位。如： http_request_duration_seconds node_memory_usage_bytes http_requests_total (for a unit-less accumulating count) 逻辑上与被测量的变量含义相同。 尽量使用基本单位，如 seconds，bytes。而不是 Milliseconds, megabytes。 Label 的命名： 依据选择的维度命名，如： region: shenzhen/guangzhou/beijing owner: user1/user2/user3 stage: extract/transform/load 5 基本单位prometheus没有任何硬编码的单位。为了更好的兼容性，应该使用基本单元。下面列出了一些带有基本单位的指标家族。但这个清单并不详尽。 家族 基本单位 备注 Time 秒 Temperature 摄氏度 由于实际原因，摄氏温度比开尔文温度更受欢迎。 Length 米 Bytes 字节 Bits 字节 为了避免不同指标混淆，总是使用字节，即使在比特位更常见的场景也是如此。 Percent 比率 值从0 - 1 ，而不是从0 - 100。 ratio仅用作disk_usage_ratio等名称的后缀。通常的指标名称遵循模式A_per_B。 Voltage 伏特 Electric current 安培 Energy 焦耳 Mass 克 “克”是首选而不是“千克”，以避免kilo前缀的问题。","categories":[{"name":"技术原理","slug":"技术原理","permalink":"http://he49816306.github.io/categories/%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"原理","slug":"原理","permalink":"http://he49816306.github.io/tags/%E5%8E%9F%E7%90%86/"},{"name":"监控","slug":"监控","permalink":"http://he49816306.github.io/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"初识Metric(指标)","slug":"first-learn-metric","date":"2023-03-08T07:17:46.000Z","updated":"2023-03-30T05:34:58.660Z","comments":true,"path":"2023/03/08/first-learn-metric/","link":"","permalink":"http://he49816306.github.io/2023/03/08/first-learn-metric/","excerpt":"","text":"初识Metric(指标)一、Prometheus简介​ Prometheus受启发于Google的Brogmon监控系统（相似的Kubernetes是从Google的Brog系统演变而来），从2012年开始由前Google工程师在Soundcloud以开源软件的形式进行研发，并且于2015年早期对外发布早期版本。2016年5月继Kubernetes之后成为第二个正式加入CNCF基金会的项目，同年6月正式发布1.0版本。2017年底发布了基于全新存储层的2.0版本，能更好地与容器平台、云平台配合。 Prometheus作为新一代的云原生监控系统，目前已经有超过650+位贡献者参与到Prometheus的研发工作上，并且超过120+项的第三方集成。 二、监控的目标​ 在《SRE: Google运维解密》一书中指出，监控系统需要能够有效的支持白盒监控和黑盒监控。通过白盒能够了解其内部的实际运行状态，通过对监控指标的观察能够预判可能出现的问题，从而对潜在的不确定因素进行优化。而黑盒监控，常见的如HTTP探针，TCP探针等，可以在系统或者服务在发生故障时能够快速通知相关的人员进行处理。通过建立完善的监控体系，从而达到以下目的： 长期趋势分析：通过对监控样本数据的持续收集和统计，对监控指标进行长期趋势分析。例如，通过对磁盘空间增长率的判断，我们可以提前预测在未来什么时间节点上需要对资源进行扩容。 对照分析：两个版本的系统运行资源使用情况的差异如何？在不同容量情况下系统的并发和负载变化如何？通过监控能够方便的对系统进行跟踪和比较。 告警：当系统出现或者即将出现故障时，监控系统需要迅速反应并通知管理员，从而能够对问题进行快速的处理或者提前预防问题的发生，避免出现对业务的影响。 故障分析与定位：当问题发生后，需要对问题进行调查和处理。通过对不同监控监控以及历史数据的分析，能够找到并解决根源问题。 数据可视化：通过可视化仪表盘能够直接获取系统的运行状态、资源使用情况、以及服务运行状态等直观的信息。 三、认识Metric Metric 指标，可以先简单理解为监控的数据。metric 是Prometheus监控的核心。 在Prometheus的存储实现上所有的监控样本都是以time-series的形式保存在Prometheus内存的TSDB（时序数据库）中，而time-series所对应的监控指标(metric)也是通过labelset进行唯一命名的。 从存储上来讲所有的监控指标metric都是相同的，但是在不同的场景下这些metric又有一些细微的差异。 例如，在Node Exporter返回的样本中指标node_load1反应的是当前系统的负载状态，随着时间的变化这个指标返回的样本数据是在不断变化的。而指标node_cpu所获取到的样本数据却不同，它是一个持续增大的值，因为其反应的是CPU的累积使用时间，从理论上讲只要系统不关机，这个值是会无限变大的。 为了能够帮助用户理解和区分这些不同监控指标之间的差异，Prometheus定义了4中不同的指标类型(metric type)：Counter（计数器）、Gauge（仪表盘）、Histogram（直方图）、Summary（摘要）。 在Exporter返回的样本数据中，其注释中也包含了该样本的类型。例如： # HELP node_cpu Seconds the cpus spent in each mode. # TYPE node_cpu counter node_cpu{cpu=&quot;cpu0&quot;,mode=&quot;idle&quot;} 362812.7890625除了以 # 开头的是注释外，其他的就是一行行的metrics了 举例： 一个Metric数据 由 名字 + labels（可选）+ 值 三部分组成 其中，名字 + labels 构成了 Metric 的唯一性。 四、Prometheus Metric 有四种类型Counter：只增不减的计数器Counter类型的指标其工作方式和计数器一样，只增不减（除非系统发生重置）。常见的监控指标，如http_requests_total，node_cpu都是Counter类型的监控指标。 一般在定义Counter类型指标的名称时推荐使用_total作为后缀。 Counter是一个简单但有强大的工具，例如我们可以在应用程序中记录某些事件发生的次数，通过以时序的形式存储这些数据，我们可以轻松的了解该事件产生速率的变化。 PromQL内置的聚合操作和函数可以让用户对这些数据进行进一步的分析： 例如，通过rate()函数获取HTTP请求量的增长率： rate(http_requests_total[5m])查询当前系统中，访问量前10的HTTP地址： topk(10, http_requests_total)Gauge：可增可减的仪表盘与Counter不同，Gauge类型的指标侧重于反应系统的当前状态。因此这类指标的样本数据可增可减。常见指标如：node_memory_MemFree（主机当前空闲的内容大小）、node_memory_MemAvailable（可用内存大小）都是Gauge类型的监控指标。 通过Gauge指标，用户可以直接查看系统的当前状态： node_memory_MemFree对于Gauge类型的监控指标，通过PromQL内置函数delta()可以获取样本在一段时间返回内的变化情况。例如，计算CPU温度在两个小时内的差异： delta(cpu_temp_celsius{host=&quot;zeus&quot;}[2h])还可以使用deriv()计算样本的线性回归模型，甚至是直接使用predict_linear()对数据的变化趋势进行预测。例如，预测系统磁盘空间在4个小时之后的剩余情况： predict_linear(node_filesystem_free{job=&quot;node&quot;}[1h], 4 * 3600)使用Histogram和Summary分析数据分布情况除了Counter和Gauge类型的监控指标以外，Prometheus还定义了Histogram和Summary的指标类型。Histogram和Summary主用用于统计和分析样本的分布情况。 在大多数情况下人们都倾向于使用某些量化指标的平均值，例如CPU的平均使用率、页面的平均响应时间。这种方式的问题很明显，以系统API调用的平均响应时间为例：如果大多数API请求都维持在100ms的响应时间范围内，而个别请求的响应时间需要5s，那么就会导致某些WEB页面的响应时间落到中位数的情况，而这种现象被称为长尾问题。 为了区分是平均的慢还是长尾的慢，最简单的方式就是按照请求延迟的范围进行分组。例如，统计延迟在010ms之间的请求数有多少而1020ms之间的请求数又有多少。通过这种方式可以快速分析系统慢的原因。Histogram和Summary都是为了能够解决这样问题的存在，通过Histogram和Summary类型的监控指标，我们可以快速了解监控样本的分布情况。 例如，指标prometheus_tsdb_wal_fsync_duration_seconds的指标类型为Summary。 它记录了Prometheus Server中wal_fsync处理的处理时间，通过访问Prometheus Server的/metrics地址，可以获取到以下监控样本数据： # HELP prometheus_tsdb_wal_fsync_duration_seconds Duration of WAL fsync. # TYPE prometheus_tsdb_wal_fsync_duration_seconds summary prometheus_tsdb_wal_fsync_duration_seconds{quantile=&quot;0.5&quot;} 0.012352463 prometheus_tsdb_wal_fsync_duration_seconds{quantile=&quot;0.9&quot;} 0.014458005 prometheus_tsdb_wal_fsync_duration_seconds{quantile=&quot;0.99&quot;} 0.017316173 prometheus_tsdb_wal_fsync_duration_seconds_sum 2.888716127000002 prometheus_tsdb_wal_fsync_duration_seconds_count 216从上面的样本中可以得知当前Prometheus Server进行wal_fsync操作的总次数为216次，耗时2.888716127000002s。其中中位数（quantile=0.5）的耗时为0.012352463，9分位数（quantile=0.9）的耗时为0.014458005s。 在Prometheus Server自身返回的样本数据中，我们还能找到类型为Histogram的监控指标prometheus_tsdb_compaction_chunk_range_bucket。 # HELP prometheus_tsdb_compaction_chunk_range Final time range of chunks on their first compaction # TYPE prometheus_tsdb_compaction_chunk_range histogram prometheus_tsdb_compaction_chunk_range_bucket{le=&quot;100&quot;} 0 prometheus_tsdb_compaction_chunk_range_bucket{le=&quot;400&quot;} 0 prometheus_tsdb_compaction_chunk_range_bucket{le=&quot;1600&quot;} 0 prometheus_tsdb_compaction_chunk_range_bucket{le=&quot;6400&quot;} 0 prometheus_tsdb_compaction_chunk_range_bucket{le=&quot;25600&quot;} 0 prometheus_tsdb_compaction_chunk_range_bucket{le=&quot;102400&quot;} 0 prometheus_tsdb_compaction_chunk_range_bucket{le=&quot;409600&quot;} 0 prometheus_tsdb_compaction_chunk_range_bucket{le=&quot;1.6384e+06&quot;} 260 prometheus_tsdb_compaction_chunk_range_bucket{le=&quot;6.5536e+06&quot;} 780 prometheus_tsdb_compaction_chunk_range_bucket{le=&quot;2.62144e+07&quot;} 780 prometheus_tsdb_compaction_chunk_range_bucket{le=&quot;+Inf&quot;} 780 prometheus_tsdb_compaction_chunk_range_sum 1.1540798e+09 prometheus_tsdb_compaction_chunk_range_count 780与Summary类型的指标相似之处在于Histogram类型的样本同样会反应当前指标的记录的总数(以_count作为后缀)以及其值的总量（以_sum作为后缀）。不同在于Histogram指标直接反应了在不同区间内样本的个数，区间通过标签len进行定义。 同时对于Histogram的指标，我们还可以通过histogram_quantile()函数计算出其值的分位数。不同在于Histogram通过histogram_quantile函数是在服务器端计算的分位数。 而Sumamry的分位数则是直接在客户端计算完成。因此对于分位数的计算而言，Summary在通过PromQL进行查询时有更好的性能表现，而Histogram则会消耗更多的资源。反之对于客户端而言Histogram消耗的资源更少。在选择这两种方式时用户应该按照自己的实际场景进行选择。","categories":[{"name":"技术原理","slug":"技术原理","permalink":"http://he49816306.github.io/categories/%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"原理","slug":"原理","permalink":"http://he49816306.github.io/tags/%E5%8E%9F%E7%90%86/"},{"name":"监控","slug":"监控","permalink":"http://he49816306.github.io/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"轻量级依赖注入框架Google Guice（2）BIND","slug":"guice-bind","date":"2022-08-03T07:54:46.000Z","updated":"2022-08-03T12:33:30.534Z","comments":true,"path":"2022/08/03/guice-bind/","link":"","permalink":"http://he49816306.github.io/2022/08/03/guice-bind/","excerpt":"","text":"轻量级依赖注入框架Google Guice（2）BIND一、前言​ 前面介绍了Google Guice的注入，跟它相辅相成的就是绑定。绑定的话，可以说是相当的重要，因为就是先有绑定这一个操作，然后才能进行注入。详细的绑定图解如下： 就像图中所述，多个模块Module可以并列、组合和嵌套。最终完成绑定，然后进行注入。 具体的绑定方法在下面逐一介绍。 二、常见的几种绑定方式1. 类名绑定通过传入类名进行绑定，最常见的绑定方式，类似于spring的@Autowired。 // 最常见的绑定方式，类似于spring的@Autowired bind(PriceService.class).to(PriceServiceImpl.class);2. 实例绑定、常量绑定( Constant Bindings) Guice提供了一种使用值对象或常量创建绑定的方法，或者直接绑定到某个具体的实例。 // 绑定到某个具体的实例 bind(PriceService.class).to(new PriceServiceImpl()); // 绑定到某个具体的数值 bind(Long.class).toInstance(1234L);3. 链接绑定( Linked binding) 在链接绑定中，Guice将类型映射到其实现。 // 最常见的绑定方式，类似于spring的@Autowired bind(PriceService.class).to(PriceServiceImpl.class); // 我们还可以将具体类映射到它的子类。 见下面的例子 bind(PriceServiceImpl.class).to(PriceServiceMock.class); // 还可以构建匿名对象 bind(PriceServiceImpl.class).toInstance(new PriceServiceImpl() { @Override public long getPrice(long orderId) { return 1234L; } });4. @Provides Annotation通过@Provides注解进行绑定，前面也提到了相关的用法。 @Provides @Named(&quot;getSupported&quot;) List&lt;String&gt; generateSupportedCurrencies() { // 通过Provides进行绑定 return Lists.newArrayList(&quot;HJJ&quot;, &quot;HYC&quot;); }当然也可以使用我们前面案例提供的方式。 // 绑定到某个生成函数 bind(Long.class).toProvider(() -&gt; 1234L);下面是toProvider提供的几种重载。 当然绑定的时候也可以传入参数，如果参数前面已经注入，则不需要再重复注入，如下。 @Provides Long generateSessionId(PriceService priceService){ return priceService.getPrice(); }5. @Named binding命名绑定，和命名注入是一样的逻辑。 @Provides @Named(&quot;getSupported&quot;) List&lt;String&gt; generateSupportedCurrencies() { // 通过Provides + Named进行绑定 return Lists.newArrayList(&quot;HJJ&quot;, &quot;HYC&quot;); } // 这个是直接绑定的例子 bind(Long.class).annotatedWith(Names.named(&quot;price&quot;)).toProvider(() -&gt; 1234L);当然和命名注入一样，可以自定义注解，这里也不再赘述了。 6. 泛型的绑定泛型的绑定需要用到TypeLiteral，下述例子进行绑定泛型列表的成员变量。 // 绑定泛型列表 bind(new TypeLiteral&lt;List&lt;String&gt;&gt;(){}) .annotatedWith(Names.named(&quot;getSupported&quot;)) .toInstance(Arrays.asList(&quot;CNY&quot;,&quot;ENR&quot;,&quot;USD&quot;));7. 集合Set绑定集合的绑定将用到前面导入的包guice-multibindings来进行实现。 &lt;dependency&gt; &lt;groupId&gt;com.google.inject.extensions&lt;/groupId&gt; &lt;artifactId&gt;guice-multibindings&lt;/artifactId&gt; &lt;version&gt;${guice.version}&lt;/version&gt; &lt;/dependency&gt;使用的话则是通过Multibinder来进行对象构建。 // 绑定相关实例 Multibinder.newSetBinder(binder(), String.class) .addBinding().toInstance(&quot;HJJ&quot;); Multibinder.newSetBinder(binder(), String.class) .addBinding().toInstance(&quot;HYC&quot;);8. Map的绑定Map的绑定是通过MapBinder来进行构建的，跟set比较类似，通过不同的binder进行构造。 // 跟set比较类似，通过不同的binder进行构造 MapBinder.newMapBinder(binder(), keyType, valueType)9. 即时绑定( Just-in-time Bindings) 由于绑定是在绑定模块中定义的，因此只要需要注入依赖关系，Guice就会使用它们。 如果不存在绑定，它可以尝试创建即时绑定。 绑定模块中存在的绑定称为显式绑定，具有更高的优先级，而即时绑定称为隐式绑定。 如果存在两种类型的绑定，则考虑使用显式绑定进行映射。 以下是三种即时绑定的示例。 就拿@ImplementedBy来说事，当一个类有多个实现的时候，可以精准的指定到采用哪个类来进行注入。 @ProvidedBy是同样的道理，标注其提供者，就不多赘述了。 值得注意的是，使用了@ImplementedBy就不需要使用bind()语句了。 类似@ImplementedBy注解，如果某个类型既使用了bind()语句，又使用了@ProvidedBy注解，那么bind()语句优先。 三、Module之间的关系 创建一个Injector可以使用多个任意多个Module，因此需要明确它们的关系。 我们初步将其分为3种关系。 1. 并列：默认顺序传递就是此关系 // 可变参数，可以放很多个模块 Guice.createInjector(new MainModule(), .......);2. 嵌套：大的Module可以嵌套任意多个子Module public class ServerModule extends AbstractModule { @Override protected void configure() { install(new MainModule()); } }值得注意的是，可以嵌套多个模块，然而主模块里面的成员会是其中所以模块的并集。例如下述情况： A模块： public class ChinaModule extends AbstractModule { @Override public void configure() { // TODO suit China Yuan Multibinder.newSetBinder(binder(), String.class) .addBinding().toInstance(&quot;CNY&quot;); } }B模块： public class GlobalModule extends AbstractModule { @Override public void configure() { // TODO USD,ENY Multibinder&lt;String&gt; multibinder = Multibinder.newSetBinder(binder(), String.class); multibinder.addBinding().toInstance(&quot;USD&quot;); multibinder.addBinding().toInstance(&quot;ENY&quot;); } }主模块： public class ServerModule extends AbstractModule { @Override public void configure() { // 加载其他Module install(new ChinaModule()); install(new GlobalModule()); } }由此可见，主模块加载了A和B两个模块，最终输出的变量结果是 USD、ENY、CNY。 这样灵活的装配模式，也是值得我们做低代码开发平台的学习。 3. 覆盖：如果有冲突的话后者覆盖前者，没有的话就都生效当需要优先使用后者时，可以采用模块覆盖的形式。 相关细节以及完整代码，如下 // 用后者覆盖前者 Module finalModule = Modules.override(new MainModule()).with(new ServerModule());四、Guice和Dagger2Guice和Dagger都是Java的依赖注入框架，他们有很多相似性，所以放到一起比较一下： 相同点： 基于Java 由Google维护（Dagger最早是Square开发的，Dagger2已经过继给了Google） 兼容JSR-330注解规范 因为兼容JSR-330，所以需要修改源码添加注解实现注入，相对于Spring通过外部配置文件的方式对源码有侵入性 不同点 Guice历史更悠久，早在JSR-330之前就诞生并影响了JSR-330标准的制定，Dagger是在JSR-330之后出现的 Guice在运行时通过反射创建依赖；Dagger在编译期提前生成依赖创建的代码 Dagger比较适合在Android上使用，因为移动平台对性能更敏感，希望反射越少越好 Dagger的API更简单，stacetrace更友好 通过对比可见，最主要区别在于Guice的依赖注入是Runtime完成的，而Dagger是CompileTime完成了大部分工作。 Guice在 Module 中放了很多表达式和语句，其实是放到了一个map中进行维系，并不会立刻执行。所以说起来整个流程花费时间最多的地方就在 getInstance方法的时候，此时会将所有的依赖、注入建立出来。 未完待续… 后面专题介绍Guice的AOP和Scope。","categories":[{"name":"技术原理","slug":"技术原理","permalink":"http://he49816306.github.io/categories/%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"原理","slug":"原理","permalink":"http://he49816306.github.io/tags/%E5%8E%9F%E7%90%86/"},{"name":"思想","slug":"思想","permalink":"http://he49816306.github.io/tags/%E6%80%9D%E6%83%B3/"},{"name":"设计模式","slug":"设计模式","permalink":"http://he49816306.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"轻量级依赖注入框架Google Guice（1）DI","slug":"guice-di","date":"2022-08-02T05:54:46.000Z","updated":"2022-08-03T11:02:19.090Z","comments":true,"path":"2022/08/02/guice-di/","link":"","permalink":"http://he49816306.github.io/2022/08/02/guice-di/","excerpt":"","text":"轻量级依赖注入框架Google Guice（1）DI一、Google Guice简介​ Google Guice (读作”juice”)是超轻量级的，下一代的，为Java 5及后续版本设计的依赖注入容器。 它在连接对象、访问中间层等方面，体现了最大程度的灵活性和可维护性。 ​ 正所谓谷歌出品，必属精品，况且Guice还出自于它的广告这种多金部门，自然也不例外。Google Guice被大量应用于谷歌内部，然后2010年开源出来。虽然业界反响并不大，但是因为它的轻量级，有些流行的开源框架（如Druid、Apollo、Elastic Search、Play2）把它作为基础的DI组件。 二、基础配置导入maven依赖。 &lt;dependency&gt; &lt;groupId&gt;com.google.inject&lt;/groupId&gt; &lt;artifactId&gt;guice&lt;/artifactId&gt; &lt;version&gt;${guice.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.inject.extensions&lt;/groupId&gt; &lt;artifactId&gt;guice-multibindings&lt;/artifactId&gt; &lt;version&gt;${guice.version}&lt;/version&gt; &lt;/dependency&gt;具体的发行版参考下述版本。 三、快速开始我们先想象有一个简单的订单支付的业务。有支付服务，订单服务，价格计算服务。 建立价格服务接口和其对应的实现 public interface PriceService { /** * &lt;p&gt;获取支持的货币&lt;/p&gt; * * @description: 获取支持的货币 * @return java.util.List&lt;java.lang.String&gt; * @author: junjie he * @create: 2022/8/2 */ List&lt;String&gt; getSupportedCurrencies(); /** * &lt;p&gt;获取价格&lt;/p&gt; * * @description: 获取价格 * @param orderId 订单号 * @return long * @author: junjie he * @create: 2022/8/2 */ long getPrice(long orderId); }建立订单服务接口和其对应的实现 public interface OrderService { /** * &lt;p&gt;发送订单&lt;/p&gt; * * @description: 发送订单 * @param orderId 订单号 * @return void * @author: junjie he * @create: 2022/8/2 */ void sendToPayment(long orderId); }建立支付服务接口和其对应的实现 public interface PaymentService { /** * &lt;p&gt;付款操作&lt;/p&gt; * * @description: 付款操作 * @param orderId 订单号 * @param price 价格 * @param sessionId 会话ID * @return void * @author: junjie he * @create: 2022/8/2 */ void pay(long orderId, long price, Object sessionId); }建立一个服务Module，将服务和模块进行关联。 在Guice中需要定义Module来进行关联，注入的配置是自写的Java类，必须继承AbstractModule抽象类，重写configure方法。 public class ServerModule extends AbstractModule { @Override protected void configure() { //相当于将实现类注入 bind(OrderService.class).to(OrderServerImpl.class); bind(PaymentService.class).to(PaymentServiceImpl.class); bind(PriceService.class).to(PriceServiceImpl.class); } }再编写一下相关的测试类，提供程序的启动入口。 public class OrderServerTest { @Inject private OrderService orderService; @Inject private PriceService priceService; @Before public void SetUp() { //利用injectMembers，将当前所需的类具现化 Guice.createInjector(new ServerModule()).injectMembers(this); } @Test public void testSendToPayment() { orderService.sendToPayment(789L); } @Test public void testSupportedCurrencies() { throw new RuntimeException( priceService.getSupportedCurrencies().toString() ); } }大功告成，接下来介绍我们的几种注入方式。 四、常见的几种注入方式 Guice注入图解如上，通过@Inject进行注入，这点跟spring还是有点类似，可以用构造方式注入，也可以直接注入到每个成员变量上，以下将列举集中注入方式。 1. 纯类型注入在price模块中添加一个price的成员变量，然后在其构造中加入@Inject注解，同时在ServerModule中加入bind来绑定该类型值。完整代码如下： // PriceServiceImpl中添加成员变量 private final Long price; // 构造做相应的改造 @Inject public PriceServiceImpl(@Named(&quot;getSupported&quot;) Provider&lt;List&lt;String&gt;&gt; supportedCurrencies, Long price) { this.supportedCurrencies = supportedCurrencies; this.price = price; } // ServerModule中添加绑定 bind(Long.class).toInstance(1234L); // 运行结果 java.lang.RuntimeException: Price=1234.SessionId=1659439200620.orderPaid=1可见price已经被绑定成了设置的1234。 2. Provider注入将上述price的成员变量，改为Provider接口提供的值。同时在ServerModule中添加相关的Provider即可完成注入，完整代码如下： // PriceServiceImpl中修改成员变量为Provider private final Provider&lt;Long&gt; price; // ServerModule中绑定为provider并用函数式进行简化 bind(Long.class).toProvider(() -&gt; 1234L); // 或者写一个 @Provides 的函数，类似于spring的bean @Provides Long generatePrice() { return 1234L; }可见，使用Provider注入会变得相当的灵活。 3. 命名注入很多时候单一注入的方式并不能满足我们的需求，这时可以使用命名注入的方式，有点指哪打哪的意思，注入的时候只会关注名字与类型的匹配，这样可读性更高，并且更灵活。 相关细节以及完整代码，如下 // 构造函数中加入 @Named(&quot;price&quot;) 来标记该字段 @Inject public PriceServiceImpl(@Named(&quot;getSupported&quot;) Provider&lt;List&lt;String&gt;&gt; supportedCurrencies, @Named(&quot;price&quot;) Long price) { this.supportedCurrencies = supportedCurrencies; this.price = price; }同时我们也可以通过采用方法注入( Method Injection) 或者 场注入( Field Injection) 这两种方式来完成我们的注入，这点和Spring的自动装载也比较类似。 相关细节以及完整代码，如下 // 下述为 方法注入( Method Injection) 方式 @Inject public void setSupportedCurrencies(@Named(&quot;getSupported&quot;) Provider&lt;List&lt;String&gt;&gt; supportedCurrencies) { this.supportedCurrencies = supportedCurrencies; } @Inject public void setPrice(@Named(&quot;price&quot;) Long price) { this.price = price; } // 下述为场注入( Field Injection) 方式 @Inject @Named(&quot;price&quot;) private Long price;注入写好了，在绑定操作的时候就必须绑定到相关命名注解才可以。 // 绑定的时候绑定到命名的注解 bind(Long.class).annotatedWith(Names.named(&quot;price&quot;)).toProvider(() -&gt; 1234L);当然可以自定义注解，来代替@Named进行使用，因为使用方法大致上是一样的，就不再进行赘述。 未完待续… 后面专题介绍Guice的绑定。","categories":[{"name":"技术原理","slug":"技术原理","permalink":"http://he49816306.github.io/categories/%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"原理","slug":"原理","permalink":"http://he49816306.github.io/tags/%E5%8E%9F%E7%90%86/"},{"name":"思想","slug":"思想","permalink":"http://he49816306.github.io/tags/%E6%80%9D%E6%83%B3/"},{"name":"设计模式","slug":"设计模式","permalink":"http://he49816306.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"浅谈控制反转与依赖注入（转载）","slug":"ioc","date":"2022-07-29T07:17:46.000Z","updated":"2022-07-29T06:11:21.672Z","comments":true,"path":"2022/07/29/ioc/","link":"","permalink":"http://he49816306.github.io/2022/07/29/ioc/","excerpt":"","text":"浅谈控制反转与依赖注入第一章：小明和他的手机从前有个人叫小明 小明有三大爱好，抽烟，喝酒…… 咳咳，不好意思，走错片场了。应该是逛知乎、玩王者农药和抢微信红包 小明的三大爱好 我们用一段简单的伪代码，来制造一个这样的小明 class Ming extends Person { private $_name; private $_age; function read() { //逛知乎 } function play() { //玩农药 } function grab() { //抢红包 } }但是，小明作为一个人类，没有办法仅靠自己就能实现以上的功能，他必须依赖一部手机，所以他买了一台iphone6，接下来我们来制造一个iphone6 class iPhone6 extends Iphone { function read($user=&quot;某人&quot;) { echo $user.&quot;打开了知乎然后编了一个故事 \\n&quot;; } function play($user=&quot;某人&quot;) { echo $user.&quot;打开了王者农药并送起了人头 \\n&quot;; } function grab($user=&quot;某人&quot;) { echo $user.&quot;开始抢红包却只抢不发 \\n&quot;; } } 小明非常珍惜自己的新手机，每天把它牢牢控制在手心里，所以小明变成了这个样子 class Ming extends Person { private $_name; private $_age; public function __construct() { $this-&gt;_name = &#39;小明&#39;; $this-&gt;_age = 26; } function read() { //…… 省略若干代码 (new iPhone6())-&gt;read($this-&gt;_name); //逛知乎 } function play() { //…… 省略若干代码 (new iPhone6())-&gt;play($this-&gt;_name);//玩农药 } function grab() { //…… 省略若干代码 (new iPhone6())-&gt;grab($this-&gt;_name);//抢红包 } } 今天是周六，小明不用上班，于是他起床，并依次逛起了知乎，玩王者农药，并抢了个红包。 $ming = new Ming(); //小明起床 $ming-&gt;read(); $ming-&gt;play(); $ming-&gt;grab(); 这个时候，我们可以在命令行里看到输出如下 小明打开了知乎然后编了一个故事 小明打开了王者农药并送起了人头 小明开始抢红包却只抢不发 这一天，小明过得很充实，他觉得自己是世界上最幸福的人。 第二章： 小明的快乐与忧伤小明和他的手机曾一起度过了一段美好的时光，一到空闲时刻，他就抱着手机，逛知乎，刷微博，玩游戏，他觉得自己根本不需要女朋友，只要有手机在身边，就满足了。 可谁能想到，一次次地系统更新彻底打碎了他的梦想，他的手机变得越来越卡顿，电池的使用寿命也越来越短，一直到某一天的寒风中，他的手机终于耐不住寒冷，头也不回地关了机。 小明很忧伤，他意识到，自己要换手机了。 为了能获得更好的使用体验，小明一咬牙，剁手了一台iphoneX，这部手机铃声很大，电量很足，还能双卡双待，小明很喜欢，但是他遇到一个问题，就是他之前过度依赖了原来那一部iPhone6，他们之间已经深深耦合在一起了，如果要换手机，他就要拿起刀来改造自己，把自己体内所有方法中的iphone6 都换成 iphoneX。 漫长的改造过程 经历了漫长的改造过程，小明终于把代码中的 iphone6 全部换成了 iphoneX。虽然很辛苦，但是小明觉得他是快乐的。 于是小明开开心心地带着手机去上班了，并在回来的路上被小偷偷走了。为了应急，小明只好重新使用那部刚刚被遗弃的iphone6，但是一想到那漫长的改造过程，小明的心里就说不出的委屈，他觉得自己过于依赖手机了，为什么每次手机出什么问题他都要去改造他自己，这不仅仅是过度耦合，简直是本末倒置，他向天空大喊，我不要再控制我的手机了。 天空中的造物主，也就是作为程序员的我，听到了他的呐喊，我告诉他，你不用再控制你的手机了，交给我来管理，把控制权交给我。这就叫做控制反转。 第三章：造物主的智慧小明听到了我的话，他既高兴，又有一点害怕，他跪下来磕了几个头，虔诚地说到：“原来您就是传说中的造物主，巴格梅克上神。我听到您刚刚说了 控制反转 四个字，就是把手机的控制权从我的手里交给你，但这只是您的想法，是一种思想罢了，要用什么办法才能实现控制反转，又可以让我继续使用手机呢？” “呵“，身为造物主的我在表现完不屑以后，扔下了四个大字，“依赖注入！” 接下来，伟大的我开始对小明进行惨无人道的改造，如下 class Ming extends Person { private $_name; private $_age; private $_phone; //将手机作为自己的成员变量 public function __construct($phone) { $this-&gt;_name = &#39;小明&#39;; $this-&gt;_age = 26; $this-&gt;_phone = $phone; echo &quot;小明起床了 \\n&quot;; } function read() { //…… 省略若干代码 $this-&gt;_phone-&gt;read($this-&gt;_name); //逛知乎 } function play() { //…… 省略若干代码 $this-&gt;_phone-&gt;play($this-&gt;_name);//玩农药 } function grab() { //…… 省略若干代码 $this-&gt;_phone-&gt;grab($this-&gt;_name);//抢红包 } } 接下来，我们来模拟运行小明的一天 $phone = new IphoneX(); //创建一个iphoneX的实例 if($phone-&gt;isBroken()){//如果iphone不可用，则使用旧版手机 $phone = new Iphone6(); } $ming = new Ming($phone);//小明不用关心是什么手机，他只要玩就行了。 $ming-&gt;read(); $ming-&gt;play(); $ming-&gt;grab();我们先看一下iphoneX 是否可以使用，如果不可以使用，则直接换成iphone6,然后唤醒小明，并把手机塞到他的手里，换句话说，把他所依赖的手机直接注入到他的身上，他不需要关心自己拿的是什么手机，他只要直接使用就可以了。 这就是依赖注入。 第四章：小明的感悟 小明的生活开始变得简单了起来，而他把省出来的时间都用来写笔记了，他在笔记本上这样写到 我曾经有很强的控制欲，过度依赖于我的手机，导致我和手机之间耦合程度太高，只要手机出现一点点问题，我都要改造我自己，这实在是既浪费时间又容易出问题。自从我把控制权交给了造物主，他每天在唤醒我以前，就已经替我选好了手机，我只要按照平时一样玩手机就可以了，根本不用关心是什么手机。即便手机出了问题，也可以由造物主直接搞定，不需要再改造我自己了，我现在买了七部手机，都交给了造物主，每天换一部，美滋滋！我也从其中获得了这样的感悟： 如果一个类A 的功能实现需要借助于类B，那么就称类B是类A的依赖，如果在类A的内部去实例化类B，那么两者之间会出现较高的耦合，一旦类B出现了问题，类A也需要进行改造，如果这样的情况较多，每个类之间都有很多依赖，那么就会出现牵一发而动全身的情况，程序会极难维护，并且很容易出现问题。要解决这个问题，就要把A类对B类的控制权抽离出来，交给一个第三方去做，把控制权反转给第三方，就称作控制反转（IOC Inversion Of Control）。控制反转是一种思想，是能够解决问题的一种可能的结果，而依赖注入（Dependency Injection）就是其最典型的实现方法。由第三方（我们称作IOC容器）来控制依赖，把他通过构造函数、属性或者工厂模式等方法，注入到类A内，这样就极大程度的对类A和类B进行了解耦。 第五章 小明的困惑有一天，小明发现自己在想阅读知乎的时候，读到了这样一行文字。 未完待续…","categories":[{"name":"技术原理","slug":"技术原理","permalink":"http://he49816306.github.io/categories/%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"原理","slug":"原理","permalink":"http://he49816306.github.io/tags/%E5%8E%9F%E7%90%86/"},{"name":"思想","slug":"思想","permalink":"http://he49816306.github.io/tags/%E6%80%9D%E6%83%B3/"},{"name":"设计模式","slug":"设计模式","permalink":"http://he49816306.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Redis分布式锁","slug":"redis-distributed-lock","date":"2021-01-04T06:21:47.000Z","updated":"2021-01-07T06:22:56.169Z","comments":true,"path":"2021/01/04/redis-distributed-lock/","link":"","permalink":"http://he49816306.github.io/2021/01/04/redis-distributed-lock/","excerpt":"","text":"一、业务背景有些业务请求，属于耗时操作，需要加锁，防止后续的并发操作，同时对数据库的数据进行操作，需要避免对之前的业务造成影响。 二、分析流程使用 Redis 作为分布式锁，将锁的状态放到 Redis 统一维护，解决集群中单机 JVM 信息不互通的问题，规定操作顺序，保护用户的数据正确。 梳理设计流程 新建注解 @interface，在注解里设定入参标志 增加 AOP 切点，扫描特定注解 建立 @Aspect 切面任务，注册 bean 和拦截特定方法 特定方法参数 ProceedingJoinPoint，对方法 pjp.proceed() 前后进行拦截 切点前进行加锁，任务执行后进行删除 key 核心步骤：加锁、解锁和续时 加锁使用了 RedisTemplate 的 opsForValue.setIfAbsent 方法，判断是否有 key，设定一个随机数 UUID.random().toString，生成一个随机数作为 value。 从 redis 中获取锁之后，对 key 设定 expire 失效时间，到期后自动释放锁。 按照这种设计，只有第一个成功设定 Key 的请求，才能进行后续的数据操作，后续其它请求由于无法获得🔐资源，将会失败结束。 超时问题担心 pjp.proceed() 切点执行的方法太耗时，导致 Redis 中的 key 由于超时提前释放了。 例如，线程 A 先获取锁，proceed 方法耗时，超过了锁超时时间，到期释放了锁，这时另一个线程 B 成功获取 Redis 锁，两个线程同时对同一批数据进行操作，导致数据不准确。 解决方案：增加一个「续时」任务不完成，锁不释放： 维护了一个定时线程池 ScheduledExecutorService，每隔 2s 去扫描加入队列中的 Task，判断是否失效时间是否快到了，公式为：【失效时间】&lt;= 【当前时间】+【失效间隔（三分之一超时）】 /** * 线程池，每个 JVM 使用一个线程去维护 keyAliveTime，定时执行 runnable */ private static final ScheduledExecutorService SCHEDULER = new ScheduledThreadPoolExecutor(1, new BasicThreadFactory.Builder().namingPattern(&quot;redisLock-schedule-pool&quot;).daemon(true).build()); static { SCHEDULER.scheduleAtFixedRate(() -&gt; { // do something to extend time }, 0, 2, TimeUnit.SECONDS); } 三、设计方案经过上面的分析，小何设计出了这个方案： 前面已经说了整体流程，这里强调一下几个核心步骤： 拦截注解 @RedisLock，获取必要的参数 加锁操作 续时操作 结束业务，释放锁 四、实操之前也有整理过 AOP 使用方法，可以参考一下 相关属性类配置业务属性枚举设定public enum RedisLockTypeEnum { /** * 自定义 key 前缀 */ ONE(&quot;Business1&quot;, &quot;Test1&quot;), TWO(&quot;Business2&quot;, &quot;Test2&quot;); private String code; private String desc; RedisLockTypeEnum(String code, String desc) { this.code = code; this.desc = desc; } public String getCode() { return code; } public String getDesc() { return desc; } public String getUniqueKey(String key) { return String.format(&quot;%s:%s&quot;, this.getCode(), key); } }任务队列保存参数 public class RedisLockDefinitionHolder { /** * 业务唯一 key */ private String businessKey; /** * 加锁时间 (秒 s) */ private Long lockTime; /** * 上次更新时间（ms） */ private Long lastModifyTime; /** * 保存当前线程 */ private Thread currentTread; /** * 总共尝试次数 */ private int tryCount; /** * 当前尝试次数 */ private int currentCount; /** * 更新的时间周期（毫秒）,公式 = 加锁时间（转成毫秒） / 3 */ private Long modifyPeriod; public RedisLockDefinitionHolder(String businessKey, Long lockTime, Long lastModifyTime, Thread currentTread, int tryCount) { this.businessKey = businessKey; this.lockTime = lockTime; this.lastModifyTime = lastModifyTime; this.currentTread = currentTread; this.tryCount = tryCount; this.modifyPeriod = lockTime * 1000 / 3; } }设定被拦截的注解名字@Retention(RetentionPolicy.RUNTIME) @Target({ElementType.METHOD, ElementType.TYPE}) public @interface RedisLockAnnotation { /** * 特定参数识别，默认取第 0 个下标 */ int lockFiled() default 0; /** * 超时重试次数 */ int tryCount() default 3; /** * 自定义加锁类型 */ RedisLockTypeEnum typeEnum(); /** * 释放时间，秒 s 单位 */ long lockTime() default 30; }核心切面拦截的操作RedisLockAspect.java 该类分成三部分来描述具体作用 Pointcut 设定/** * @annotation 中的路径表示拦截特定注解 */ @Pointcut(&quot;@annotation(cn.sevenyuan.demo.aop.lock.RedisLockAnnotation)&quot;) public void redisLockPC() { }Around 前后进行加锁和释放锁前面步骤定义了我们想要拦截的切点，下一步就是在切点前后做一些自定义操作： @Around(value = &quot;redisLockPC()&quot;) public Object around(ProceedingJoinPoint pjp) throws Throwable { // 解析参数 Method method = resolveMethod(pjp); RedisLockAnnotation annotation = method.getAnnotation(RedisLockAnnotation.class); RedisLockTypeEnum typeEnum = annotation.typeEnum(); Object[] params = pjp.getArgs(); String ukString = params[annotation.lockFiled()].toString(); // 省略很多参数校验和判空 String businessKey = typeEnum.getUniqueKey(ukString); String uniqueValue = UUID.randomUUID().toString(); // 加锁 Object result = null; try { boolean isSuccess = redisTemplate.opsForValue().setIfAbsent(businessKey, uniqueValue); if (!isSuccess) { throw new Exception(&quot;You can&#39;t do it，because another has get the lock =-=&quot;); } redisTemplate.expire(businessKey, annotation.lockTime(), TimeUnit.SECONDS); Thread currentThread = Thread.currentThread(); // 将本次 Task 信息加入「延时」队列中 holderList.add(new RedisLockDefinitionHolder(businessKey, annotation.lockTime(), System.currentTimeMillis(), currentThread, annotation.tryCount())); // 执行业务操作 result = pjp.proceed(); // 线程被中断，抛出异常，中断此次请求 if (currentThread.isInterrupted()) { throw new InterruptedException(&quot;You had been interrupted =-=&quot;); } } catch (InterruptedException e ) { log.error(&quot;Interrupt exception, rollback transaction&quot;, e); throw new Exception(&quot;Interrupt exception, please send request again&quot;); } catch (Exception e) { log.error(&quot;has some error, please check again&quot;, e); } finally { // 请求结束后，强制删掉 key，释放锁 redisTemplate.delete(businessKey); log.info(&quot;release the lock, businessKey is [&quot; + businessKey + &quot;]&quot;); } return result; }上述流程简单总结一下： 解析注解参数，获取注解值和方法上的参数值 redis 加锁并且设置超时时间 将本次 Task 信息加入「延时」队列中，进行续时，方式提前释放锁 加了一个线程中断标志 结束请求，finally 中释放锁 续时操作这里用了 ScheduledExecutorService，维护了一个线程，不断对任务队列中的任务进行判断和延长超时时间： // 扫描的任务队列 private static ConcurrentLinkedQueue&lt;RedisLockDefinitionHolder&gt; holderList = new ConcurrentLinkedQueue(); /** * 线程池，维护keyAliveTime */ private static final ScheduledExecutorService SCHEDULER = new ScheduledThreadPoolExecutor(1, new BasicThreadFactory.Builder().namingPattern(&quot;redisLock-schedule-pool&quot;).daemon(true).build()); { // 两秒执行一次「续时」操作 SCHEDULER.scheduleAtFixedRate(() -&gt; { // 这里记得加 try-catch，否者报错后定时任务将不会再执行=-= Iterator&lt;RedisLockDefinitionHolder&gt; iterator = holderList.iterator(); while (iterator.hasNext()) { RedisLockDefinitionHolder holder = iterator.next(); // 判空 if (holder == null) { iterator.remove(); continue; } // 判断 key 是否还有效，无效的话进行移除 if (redisTemplate.opsForValue().get(holder.getBusinessKey()) == null) { iterator.remove(); continue; } // 超时重试次数，超过时给线程设定中断 if (holder.getCurrentCount() &gt; holder.getTryCount()) { holder.getCurrentTread().interrupt(); iterator.remove(); continue; } // 判断是否进入最后三分之一时间 long curTime = System.currentTimeMillis(); boolean shouldExtend = (holder.getLastModifyTime() + holder.getModifyPeriod()) &lt;= curTime; if (shouldExtend) { holder.setLastModifyTime(curTime); redisTemplate.expire(holder.getBusinessKey(), holder.getLockTime(), TimeUnit.SECONDS); log.info(&quot;businessKey : [&quot; + holder.getBusinessKey() + &quot;], try count : &quot; + holder.getCurrentCount()); holder.setCurrentCount(holder.getCurrentCount() + 1); } } }, 0, 2, TimeUnit.SECONDS); }这段代码，用来实现设计图中虚线框的思想，避免一个请求十分耗时，导致提前释放了锁。 这里加了「线程中断」Thread#interrupt，希望超过重试次数后，能让线程中断（未经严谨测试，仅供参考哈哈哈哈） 不过建议如果遇到这么耗时的请求，还是能够从根源上查找，分析耗时路径，进行业务优化或其它处理，避免这些耗时操作。 所以记得多打点 Log，分析问题时可以更快一点。如何使用SpringBoot AOP 记录操作日志、异常日志？ 五、开始测试在一个入口方法中，使用该注解，然后在业务中模拟耗时请求，使用了 Thread#sleep @GetMapping(&quot;/testRedisLock&quot;) @RedisLockAnnotation(typeEnum = RedisLockTypeEnum.ONE, lockTime = 3) public Book testRedisLock(@RequestParam(&quot;userId&quot;) Long userId) { try { log.info(&quot;睡眠执行前&quot;); Thread.sleep(10000); log.info(&quot;睡眠执行后&quot;); } catch (Exception e) { // log error log.info(&quot;has some error&quot;, e); } return null; }使用时，在方法上添加该注解，然后设定相应参数即可，根据 typeEnum 可以区分多种业务，限制该业务被同时操作。 测试结果： 2021-01-04 14:55:50.864 INFO 9326 --- [nio-8081-exec-1] c.s.demo.controller.BookController : 睡眠执行前 2021-01-04 14:55:52.855 INFO 9326 --- [k-schedule-pool] c.s.demo.aop.lock.RedisLockAspect : businessKey : [Business1:1024], try count : 0 2021-01-04 14:55:54.851 INFO 9326 --- [k-schedule-pool] c.s.demo.aop.lock.RedisLockAspect : businessKey : [Business1:1024], try count : 1 2021-01-04 14:55:56.851 INFO 9326 --- [k-schedule-pool] c.s.demo.aop.lock.RedisLockAspect : businessKey : [Business1:1024], try count : 2 2021-01-04 14:55:58.852 INFO 9326 --- [k-schedule-pool] c.s.demo.aop.lock.RedisLockAspect : businessKey : [Business1:1024], try count : 3 2021-01-04 14:56:00.857 INFO 9326 --- [nio-8081-exec-1] c.s.demo.controller.BookController : has some error java.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) [na:1.8.0_221]我这里测试的是重试次数过多，失败的场景，如果减少睡眠时间，就能让业务正常执行。 如果同时请求，你将会发现以下错误信息： 2021-01-04 14:58:00.857 INFO 9326 --- [nio-8081-exec-9] c.s.demo.aop.lock.RedisLockAspect : has some error,please check again java.lang.Exception: You can&#39;t do it,because another has get the lock =-=表示我们的锁🔐的确生效了，避免了重复请求。 六、总结对于耗时业务和核心数据，不能让重复的请求同时操作数据，避免数据的不正确，所以要使用分布式锁来对它们进行保护。 再来梳理一下设计流程： 新建注解 @interface，在注解里设定入参标志 增加 AOP 切点，扫描特定注解 建立 @Aspect 切面任务，注册 bean 和拦截特定方法 特定方法参数 ProceedingJoinPoint，对方法 pjp.proceed() 前后进行拦截 切点前进行加锁，任务执行后进行删除 key 本次学习是通过 测试小姐姐 对操作进行并发测试，从中引申出分布式锁的概念和具体实现，然后写了一份简化版的业务处理。对于之前没考虑到的「续时」操作，这里使用了守护线程来定时判断和延长超时时间，避免了锁提前释放。 于是乎，同时回顾了三个知识点： 1、AOP 的实现和常用方法 2、定时线程池 ScheduledExecutorService 的使用和参数含义 3、线程 Thread#interrupt 的含义以及用法（这个挺有意思的，可以深入再学习一下） 具体代码放在了之前学习 SpringBoot 的项目中，感兴趣的可以克隆一下，使用这个 Redis 🔐","categories":[{"name":"并发操作","slug":"并发操作","permalink":"http://he49816306.github.io/categories/%E5%B9%B6%E5%8F%91%E6%93%8D%E4%BD%9C/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://he49816306.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"优化","slug":"优化","permalink":"http://he49816306.github.io/tags/%E4%BC%98%E5%8C%96/"},{"name":"并发","slug":"并发","permalink":"http://he49816306.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"面试官：如果让你来设计一个 MQ，该如何下手？","slug":"message-queue","date":"2021-01-04T06:21:47.000Z","updated":"2022-08-04T01:56:35.942Z","comments":true,"path":"2021/01/04/message-queue/","link":"","permalink":"http://he49816306.github.io/2021/01/04/message-queue/","excerpt":"","text":"本文主要讲解 MQ 的通用知识，让大家先弄明白：如果让你来设计一个 MQ，该如何下手？需要考虑哪些问题？又有哪些技术挑战？ 有了这个基础后，我相信后面再讲 Kafka 和 RocketMQ 这两种具体的消息中间件时，大家能很快地抓住主脉络，同时分辨出它们各自的特点。 对于 MQ 来说，不管是 RocketMQ、Kafka 还是其他消息队列，它们的本质都是：一发一存一消费。下面我们以这个本质作为根，一起由浅入深地聊聊 MQ。 01 从 MQ 的本质说起将 MQ 掰开了揉碎了来看，都是「一发一存一消费」，再直白点就是一个「转发器」。 生产者先将消息投递一个叫做「队列」的容器中，然后再从这个容器中取出消息，最后再转发给消费者，仅此而已。 上面这个图便是消息队列最原始的模型，它包含了两个关键词：消息和队列。 1、消息：就是要传输的数据，可以是最简单的文本字符串，也可以是自定义的复杂格式（只要能按预定格式解析出来即可）。 2、队列：大家应该再熟悉不过了，是一种先进先出数据结构。它是存放消息的容器，消息从队尾入队，从队头出队，入队即发消息的过程，出队即收消息的过程。 02 原始模型的进化 再看今天我们最常用的消息队列产品（RocketMQ、Kafka 等等），你会发现：它们都在最原始的消息模型上做了扩展，同时提出了一些新名词，比如：主题（topic）、分区（partition）、队列（queue）等等。 要彻底理解这些五花八门的新概念，我们化繁为简，先从消息模型的演进说起（道理好比：架构从来不是设计出来的，而是演进而来的） 2.1 队列模型最初的消息队列就是上一节讲的原始模型，它是一个严格意义上的队列（Queue）。消息按照什么顺序写进去，就按照什么顺序读出来。不过，队列没有 “读” 这个操作，读就是出队，从队头中 “删除” 这个消息。 这便是队列模型：它允许多个生产者往同一个队列发送消息。但是，如果有多个消费者，实际上是竞争的关系，也就是一条消息只能被其中一个消费者接收到，读完即被删除。 2.2 发布-订阅模型如果需要将一份消息数据分发给多个消费者，并且每个消费者都要求收到全量的消息。很显然，队列模型无法满足这个需求。 一个可行的方案是：为每个消费者创建一个单独的队列，让生产者发送多份。这种做法比较笨，而且同一份数据会被复制多份，也很浪费空间。 为了解决这个问题，就演化出了另外一种消息模型：发布-订阅模型。 在发布-订阅模型中，存放消息的容器变成了 “主题”，订阅者在接收消息之前需要先 “订阅主题”。最终，每个订阅者都可以收到同一个主题的全量消息。 仔细对比下它和 “队列模式” 的异同：生产者就是发布者，队列就是主题，消费者就是订阅者，无本质区别。唯一的不同点在于：一份消息数据是否可以被多次消费。 2.3 小结最后做个小结，上面两种模型说白了就是：单播和广播的区别。而且，当发布-订阅模型中只有 1 个订阅者时，它和队列模型就一样了，因此在功能上是完全兼容队列模型的。 这也解释了为什么现代主流的 RocketMQ、Kafka 都是直接基于发布-订阅模型实现的？此外，RabbitMQ 中之所以有一个 Exchange 模块？其实也是为了解决消息的投递问题，可以变相实现发布-订阅模型。 包括大家接触到的 “消费组”、“集群消费”、“广播消费” 这些概念，都和上面这两种模型相关，以及在应用层面大家最常见的情形：组间广播、组内单播，也属于此范畴。 所以，先掌握一些共性的理论，对于大家再去学习各个消息中间件的具体实现原理时，其实能更好地抓住本质，分清概念。 03 透过模型看 MQ 的应用场景 目前，MQ 的应用场景非常多，大家能倒背如流的是：系统解耦、异步通信和流量削峰。除此之外，还有延迟通知、最终一致性保证、顺序消息、流式处理等等。 那到底是先有消息模型，还是先有应用场景呢？答案肯定是：先有应用场景（也就是先有问题），再有消息模型，因为消息模型只是解决方案的抽象而已。 MQ 经过 30 多年的发展，能从最原始的队列模型发展到今天百花齐放的各种消息中间件（平台级的解决方案），我觉得万变不离其宗，还是得益于：消息模型的适配性很广。 我们试着重新理解下消息队列的模型。它其实解决的是：生产者和消费者的通信问题。那它对比 RPC 有什么联系和区别呢？ 通过对比，能很明显地看出两点差异： 1、引入 MQ 后，由之前的一次 RPC 变成了现在的两次 RPC，而且生产者只跟队列耦合，它根本无需知道消费者的存在。 2、多了一个中间节点「队列」进行消息转储，相当于将同步变成了异步。 再返过来思考 MQ 的所有应用场景，就不难理解 MQ 为什么适用了？因为这些应用场景无外乎都利用了上面两个特性。 举一个实际例子，比如说电商业务中最常见的「订单支付」场景：在订单支付成功后，需要更新订单状态、更新用户积分、通知商家有新订单、更新推荐系统中的用户画像等等。 引入 MQ 后，订单支付现在只需要关注它最重要的流程：更新订单状态即可。其他不重要的事情全部交给 MQ 来通知。这便是 MQ 解决的最核心的问题：系统解耦。 改造前订单系统依赖 3 个外部系统，改造后仅仅依赖 MQ，而且后续业务再扩展（比如：营销系统打算针对支付用户奖励优惠券），也不涉及订单系统的修改，从而保证了核心流程的稳定性，降低了维护成本。 这个改造还带来了另外一个好处：因为 MQ 的引入，更新用户积分、通知商家、更新用户画像这些步骤全部变成了异步执行，能减少订单支付的整体耗时，提升订单系统的吞吐量。这便是 MQ 的另一个典型应用场景：异步通信。 除此以外，由于队列能转储消息，对于超出系统承载能力的场景，可以用 MQ 作为 “漏斗” 进行限流保护，即所谓的流量削峰。 我们还可以利用队列本身的顺序性，来满足消息必须按顺序投递的场景；利用队列 + 定时任务来实现消息的延时消费 …… MQ 其他的应用场景基本类似，都能回归到消息模型的特性上，找到它适用的原因，这里就不一一分析了。 总之，就是建议大家多从复杂多变的实践场景再回归到理论层面进行思考和抽象，这样能吃得更透。 04 如何设计一个 MQ？ 了解了上面这些理论知识以及应用场景后，下面我们再一起看下：到底如何设计一个 MQ？ 4.1 MQ 的雏形我们还是先从简单版的 MQ 入手，如果只是实现一个很粗糙的 MQ，完全不考虑生产环境的要求，该如何设计呢？ 文章开头说过，任何 MQ 无外乎：一发一存一消费，这是 MQ 最核心的功能需求。另外，从技术维度来看 MQ 的通信模型，可以理解成：两次 RPC + 消息转储。 有了这些理解，我相信只要有一定的编程基础，不用 1 个小时就能写出一个 MQ 雏形： 1、直接利用成熟的 RPC 框架（Dubbo 或者 Thrift），实现两个接口：发消息和读消息。 2、消息放在本地内存中即可，数据结构可以用 JDK 自带的 ArrayBlockingQueue 。 4.2 写一个适用于生产环境的 MQ当然，我们的目标绝不止于一个 MQ 雏形，而是希望实现一个可用于生产环境的消息中间件，那难度肯定就不是一个量级了，具体我们该如何下手呢？ 1、先把握这个问题的关键点 假如我们还是只考虑最基础的功能：发消息、存消息、消费消息（支持发布-订阅模式）。 那在生产环境中，这些基础功能将面临哪些挑战呢？我们能很快想到下面这些： 1、高并发场景下，如何保证收发消息的性能？ 2、如何保证消息服务的高可用和高可靠？ 3、如何保证服务是可以水平任意扩展的？ 4、如何保证消息存储也是水平可扩展的？ 5、各种元数据（比如集群中的各个节点、主题、消费关系等）如何管理，需不需要考虑数据的一致性？ 可见，高并发场景下的三高问题在你设计一个 MQ 时都会遇到，「如何满足高性能、高可靠等非功能性需求」才是这个问题的关键所在。 2、整体设计思路 先来看下整体架构，会涉及三类角色： 另外，将「一发一存一消费」这个核心流程进一步细化后，比较完整的数据流如下： 基于上面两个图，我们可以很快明确出 3 类角色的作用，分别如下： 1、Broker（服务端）：MQ 中最核心的部分，是 MQ 的服务端，核心逻辑几乎全在这里，它为生产者和消费者提供 RPC 接口，负责消息的存储、备份和删除，以及消费关系的维护等。 2、Producer（生产者）：MQ 的客户端之一，调用 Broker 提供的 RPC 接口发送消息。 3、Consumer（消费者）：MQ 的另外一个客户端，调用 Broker 提供的 RPC 接口接收消息，同时完成消费确认。 3、详细设计 下面，再展开讨论下一些具体的技术难点和可行的解决方案。 难点1：RPC 通信 解决的是 Broker 与 Producer 以及 Consumer 之间的通信问题。如果不重复造轮子，直接利用成熟的 RPC 框架 Dubbo 或者 Thrift 实现即可，这样不需要考虑服务注册与发现、负载均衡、通信协议、序列化方式等一系列问题了。 当然，你也可以基于 Netty 来做底层通信，用 Zookeeper、Euraka 等来做注册中心，然后自定义一套新的通信协议（类似 Kafka），也可以基于 AMQP 这种标准化的 MQ 协议来做实现（类似 RabbitMQ）。对比直接用 RPC 框架，这种方案的定制化能力和优化空间更大。 \\难点2：\\高可用设计** 高可用主要涉及两方面：Broker 服务的高可用、存储方案的高可用。可以拆开讨论。 Broker 服务的高可用，只需要保证 Broker 可水平扩展进行集群部署即可，进一步通过服务自动注册与发现、负载均衡、超时重试机制、发送和消费消息时的 ack 机制来保证。 存储方案的高可用有两个思路：1）参考 Kafka 的分区 + 多副本模式，但是需要考虑分布式场景下数据复制和一致性方案（类似 Zab、Raft等协议），并实现自动故障转移；2）还可以用主流的 DB、分布式文件系统、带持久化能力的 KV 系统，它们都有自己的高可用方案。 难点3：存储设计 消息的存储方案是 MQ 的核心部分，可靠性保证已经在高可用设计中谈过了，可靠性要求不高的话直接用内存或者分布式缓存也可以。这里重点说一下存储的高性能如何保证？这个问题的决定因素在于存储结构的设计。 目前主流的方案是：追加写日志文件（数据部分） + 索引文件的方式（很多主流的开源 MQ 都是这种方式），索引设计上可以考虑稠密索引或者稀疏索引，查找消息可以利用跳转表、二份查找等，还可以通过操作系统的页缓存、零拷贝等技术来提升磁盘文件的读写性能。 如果不追求很高的性能，也可以考虑现成的分布式文件系统、KV 存储或者数据库方案。 \\难点4：\\消费关系管理** 为了支持发布-订阅的广播模式，Broker 需要知道每个主题都有哪些 Consumer 订阅了，基于这个关系进行消息投递。 由于 Broker 是集群部署的，所以消费关系通常维护在公共存储上，可以基于 Zookeeper、Apollo 等配置中心来管理以及进行变更通知。 \\难点5：\\高性能设计** 存储的高性能前面已经谈过了，当然还可以从其他方面进一步优化性能。 比如 Reactor 网络 IO 模型、业务线程池的设计、生产端的批量发送、Broker 端的异步刷盘、消费端的批量拉取等等。 4.3 小结再总结下，要回答好：如何设计一个 MQ？ 1、需要从功能性需求（收发消息）和非功能性需求（高性能、高可用、高扩展等）两方面入手。 2、功能性需求不是重点，能覆盖 MQ 最基础的功能即可，至于延时消息、事务消息、重试队列等高级特性只是锦上添花的东西。 3、最核心的是：能结合功能性需求，理清楚整体的数据流，然后顺着这个思路去考虑非功能性的诉求如何满足，这才是技术难点所在。 05 写在最后 这篇文章从 MQ 一发一存一消费这个本质出发，讲解了消息模型的演进过程，这是 MQ 最核心的理论基础。基于此，大家也能更容易理解 MQ 的各种新名词以及应用场景。 最后通过回答：如何设计一个 MQ？目的是让大家对 MQ 的核心组件和技术难点有一个清晰的认识。另外，带着这个问题的答案再去学习 Kafka、RocketMQ 等具体的消息中间件时，也会更有侧重点。","categories":[{"name":"并发操作","slug":"并发操作","permalink":"http://he49816306.github.io/categories/%E5%B9%B6%E5%8F%91%E6%93%8D%E4%BD%9C/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"http://he49816306.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"优化","slug":"优化","permalink":"http://he49816306.github.io/tags/%E4%BC%98%E5%8C%96/"},{"name":"并发","slug":"并发","permalink":"http://he49816306.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"FutureTask（附源码解析）","slug":"future-task","date":"2020-06-19T07:17:46.000Z","updated":"2021-01-08T01:23:27.145Z","comments":true,"path":"2020/06/19/future-task/","link":"","permalink":"http://he49816306.github.io/2020/06/19/future-task/","excerpt":"","text":"FutureTask源码简介实现了Future、Runnable接口，可以看成一个带执行结果的线程任务；代码很简单，就不说太多了，有些基础请私下问我，或者找度娘 成员变量 private volatile int state; private static final int NEW = 0; private static final int COMPLETING = 1; private static final int NORMAL = 2; private static final int EXCEPTIONAL = 3; private static final int CANCELLED = 4; private static final int INTERRUPTING = 5; private static final int INTERRUPTED = 6; private Callable&lt;V&gt; callable; private Object outcome; private volatile Thread runner; private volatile WaitNode waiters; private static final sun.misc.Unsafe U = sun.misc.Unsafe.getUnsafe(); private static final long STATE; private static final long RUNNER; private static final long WAITERS; static { try { STATE = U.objectFieldOffset (FutureTask.class.getDeclaredField(&quot;state&quot;)); RUNNER = U.objectFieldOffset (FutureTask.class.getDeclaredField(&quot;runner&quot;)); WAITERS = U.objectFieldOffset (FutureTask.class.getDeclaredField(&quot;waiters&quot;)); } catch (ReflectiveOperationException e) { throw new Error(e); } Class&lt;?&gt; ensureLoaded = LockSupport.class; }关键信息解读 state，waiters， runner都可以做原子操作（Unsafe类） state 有7种状态，0 可执行态，1是执行完毕态，2是可以获取结果状态，3是执行出现异常，4,5是未执行取消状态，6是执行过程中取消状态 callable 具体执行动作 outcome 执行结果 runner 动作执行所在线程 waiters 单向链表，表头，内部含有线程信息；表示获取结果的挂起线程队列 成员方法构造方法可以执行callble或者runnable对象，runnable对象使用适配器的方式，是配成新的callble对象，并且传入的result为结果；并确定当前状态为new，可执行状态 public FutureTask(Callable&lt;V&gt; callable) { if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; } public FutureTask(Runnable runnable, V result) { this.callable = Executors.callable(runnable, result); this.state = NEW; }report方法如果正常执行完毕，则返回执行结果，否则，根据状态抛出异常 private V report(int s) throws ExecutionException { Object x = outcome; if (s == NORMAL) return (V)x; if (s &gt;= CANCELLED) throw new CancellationException(); throw new ExecutionException((Throwable)x); }状态判断根据state对状态进行判断 public boolean isCancelled() { return state &gt;= CANCELLED; } public boolean isDone() { return state != NEW; }cancel任务用户主动取消任务，根据用户是否可打断、任务是否执行，来改变状态 4,5,6 public boolean cancel(boolean mayInterruptIfRunning) { if (!(state == NEW &amp;&amp; U.compareAndSwapInt(this, STATE, NEW, mayInterruptIfRunning ? INTERRUPTING : CANCELLED))) return false; try { // in case call to interrupt throws exception if (mayInterruptIfRunning) { try { Thread t = runner; if (t != null) t.interrupt(); } finally { // final state U.putOrderedInt(this, STATE, INTERRUPTED); } } } finally { finishCompletion(); } return true; }get获取执行结果获取任务执行结果，最多等待时间模式，和无线等待时间模式 public V get() throws InterruptedException, ExecutionException { int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s); } /** * @throws CancellationException {@inheritDoc} */ public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException { if (unit == null) throw new NullPointerException(); int s = state; if (s &lt;= COMPLETING &amp;&amp; (s = awaitDone(true, unit.toNanos(timeout))) &lt;= COMPLETING) throw new TimeoutException(); return report(s); }set执行结果设置执行结果，如果是执行时出现异常，则结果为异常对象，否则执行结果为正常运算结果；并进行状态置换，1是一个临时态，2,3是最终结果态 protected void set(V v) { if (U.compareAndSwapInt(this, STATE, NEW, COMPLETING)) { outcome = v; U.putOrderedInt(this, STATE, NORMAL); finishCompletion(); } } protected void setException(Throwable t) { if (U.compareAndSwapInt(this, STATE, NEW, COMPLETING)) { outcome = t; U.putOrderedInt(this, STATE, EXCEPTIONAL); finishCompletion(); } }任务执行项具体执行任务动作，run执行返回结果，runAndReset执行不带结果，可再次执行 public void run() { if (state != NEW || !U.compareAndSwapObject(this, RUNNER, null, Thread.currentThread())) return; try { Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) { V result; boolean ran; try { result = c.call(); ran = true; } catch (Throwable ex) { result = null; ran = false; setException(ex); } if (ran) set(result); } } finally { runner = null; int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); } } protected boolean runAndReset() { if (state != NEW || !U.compareAndSwapObject(this, RUNNER, null, Thread.currentThread())) return false; boolean ran = false; int s = state; try { Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; s == NEW) { try { c.call(); // don&#39;t set result ran = true; } catch (Throwable ex) { setException(ex); } } } finally { runner = null; s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); } return ran &amp;&amp; s == NEW; } 检查状态是否是可执行，并cas设置线程对象从null到当前线程 进行callable对象执行，如果出现异常，则设置异常结果，正常执行，返回正常结果 最终设置线程为空，如果状态执行时状态发生了变化，处理可能的取消打断操作 finishCompletion方法结束任务方法，执行结束，打断结束，取消结束 waiters节点置空，并且清除队列，并且唤醒每个非空线程节点，callable对象置空；done方法可被继承，本类中什么都不做 private void finishCompletion() { for (WaitNode q; (q = waiters) != null;) { if (U.compareAndSwapObject(this, WAITERS, q, null)) { for (;;) { Thread t = q.thread; if (t != null) { q.thread = null; LockSupport.unpark(t); } WaitNode next = q.next; if (next == null) break; q.next = null; q = next; } break; } } done(); callable = null; }awaitDone方法等待获取执行结果方法，传入参数有两种，（false， 0） （true，大于0的整数值）；自旋处理 private int awaitDone(boolean timed, long nanos) throws InterruptedException { long startTime = 0L; WaitNode q = null; boolean queued = false; for (;;) { int s = state; if (s &gt; COMPLETING) { if (q != null) q.thread = null; return s; } else if (s == COMPLETING) Thread.yield(); else if (Thread.interrupted()) { removeWaiter(q); throw new InterruptedException(); } else if (q == null) { if (timed &amp;&amp; nanos &lt;= 0L) return s; q = new WaitNode(); } else if (!queued) queued = U.compareAndSwapObject(this, WAITERS,q.next = waiters, q); else if (timed) { final long parkNanos; if (startTime == 0L) { startTime = System.nanoTime(); if (startTime == 0L) startTime = 1L; parkNanos = nanos; } else { long elapsed = System.nanoTime() - startTime; if (elapsed &gt;= nanos) { removeWaiter(q); return state; } parkNanos = nanos - elapsed; } if (state &lt; COMPLETING) LockSupport.parkNanos(this, parkNanos); } else LockSupport.park(this); } } 自旋过程按照下面书序来执行 状态判断，有3中状态判断：已有结果态，马上有结果态，获取结果被打断状态 状态大于1，不是有结果了，就是异常了，就是被主动取消了，这时直接返回结果；状态等于1表示马上就到2或者3状态，下个循环就是状态大于1，直接返回结果 如果线程正在执行，且被打断，重置打断状态，并且异常当前线程节点，抛出打断异常 新建当前线程获取结果排队节点 加入获取结果队列中，并且置为waiters，之前waiters值为next指向节点 进行获取，有限时间内获取，或者无限制时间获取 如果有限时间内获取，如果超时，返回当前状态，如果未超时且当前状态在正在执行状态，则线程挂起计算时间 不限制时间获取，则直接等待 removeWaiter方法自旋处理，删除节点线程属性为空的节点 private void removeWaiter(WaitNode node) { if (node != null) { node.thread = null; retry: for (;;) { // restart on removeWaiter race for (WaitNode pred = null, q = waiters, s; q != null; q = s) { s = q.next; if (q.thread != null) pred = q; else if (pred != null) { pred.next = s; if (pred.thread == null) continue retry; } else if (!U.compareAndSwapObject(this, WAITERS, q, s)) continue retry; } break; } } }处理思路： 如果当前第一个节点的线程为空，则把下个线程置为头节点，如果还空继续此过程，知道头节点线程不为空，这是pred指向头，q为头下个节点，s为q下个节点 如果q的线程为空，则把pred的next指向s 如果q的线程不为空，则继续移动这3个节点对象，直到q为空，退出自旋 源码总结： 获取结果为阻塞过程，会挂起线程；等待结果执行完毕会被全部唤醒 线程排队队列为单向链表，有指向下个节点属性；每次插入链表头部 执行过程，进行结果处理，和唤醒链表中节点线程 执行一次带结果动作，或者重复执行不带结果动作","categories":[{"name":"技术原理","slug":"技术原理","permalink":"http://he49816306.github.io/categories/%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/"}],"tags":[{"name":"原理","slug":"原理","permalink":"http://he49816306.github.io/tags/%E5%8E%9F%E7%90%86/"},{"name":"源码","slug":"源码","permalink":"http://he49816306.github.io/tags/%E6%BA%90%E7%A0%81/"},{"name":"多线程","slug":"多线程","permalink":"http://he49816306.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"大话CY的那些日子","slug":"cy-gossip","date":"2020-06-19T06:21:47.000Z","updated":"2021-01-07T08:21:57.078Z","comments":true,"path":"2020/06/19/cy-gossip/","link":"","permalink":"http://he49816306.github.io/2020/06/19/cy-gossip/","excerpt":"","text":"谈谈CY的日子其实还是很开心的拉。只是现在看到阿喵更开心~~ PS：不过阿喵 虽然被鸡哥哥坑掉了，但是后面还是去了hz，开发了云平台，还是很不错滴拉。！","categories":[{"name":"生活日常","slug":"生活日常","permalink":"http://he49816306.github.io/categories/%E7%94%9F%E6%B4%BB%E6%97%A5%E5%B8%B8/"}],"tags":[{"name":"闲聊","slug":"闲聊","permalink":"http://he49816306.github.io/tags/%E9%97%B2%E8%81%8A/"}]},{"title":"十大经典排序算法整理汇总（附代码）","slug":"sort-algorithms","date":"2020-02-16T07:09:23.000Z","updated":"2020-06-18T09:13:57.998Z","comments":true,"path":"2020/02/16/sort-algorithms/","link":"","permalink":"http://he49816306.github.io/2020/02/16/sort-algorithms/","excerpt":"","text":"经常即将开始！！！ 前言本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。 本文并不会详细讲解每种排序算法的原理，网上有很多很好的教程，大家可以自己去搜了看。 最后我还亲自手写了十种排序算法的 c++ 代码，大家可以用来通过 LeetCode 912. 排序数组 这道题。 性质汇总 如果发现表中有错误，请留言告知。 算法 最好 最坏 平均 空间 稳定性 是否基于比较 冒泡排序 $O(n)$ $O(n^2)$ $O(n^2)$ $O(1)$ $\\checkmark$ $\\checkmark$ 选择排序 $O(n^2)$ $O(n^2)$ $O(n^2)$ $O(1)$ $\\times$ $\\checkmark$ 插入排序 $O(n)$ $O(n^2)$ $O(n^2)$ $O(1)$ $\\checkmark$ $\\checkmark$ 快速排序 $O(n\\log n)$ $O(n^2)$ $O(n\\log n)$ $O(\\log n)$~$O(n)$ $\\times$ $\\checkmark$ 归并排序 $O(n\\log n)$ $O(n\\log n)$ $O(n\\log n)$ $O(n)$ $\\checkmark$ $\\checkmark$ 希尔排序 $O(n^{1.3})$ $O(n^2)$ $O(n\\log n)$~$O(n^2)$ $O(1)$ $\\times$ $\\checkmark$ 计数排序 $O(n+k)$ $O(n+k)$ $O(n+k)$ $O(n+k)$ $\\checkmark$ $\\times$ 基数排序 $O(nk)$ $O(nk)$ $O(nk)$ $O(n+k)$ $\\checkmark$ $\\times$ 桶排序 $O(n)$ $O(n)$ $O(n)$ $O(n+m)$ $\\checkmark$ $\\times$ 堆排序 $O(n\\log n)$ $O(n\\log n)$ $O(n\\log n)$ $O(1)$ $\\times$ $\\checkmark$ 如果表格显示有问题的话，还可以直接看下面的汇总图： 维基百科我觉得还是英文维基百科讲的比较详细、严谨。如果大家看的比较累的话，可以自己百度搜索相应的教程。 冒泡排序https://en.wikipedia.org/wiki/Bubble_sort 选择排序https://en.wikipedia.org/wiki/Selection_sort 插入排序https://en.wikipedia.org/wiki/Insertion_sort 快速排序https://en.wikipedia.org/wiki/Quicksort 归并排序https://en.wikipedia.org/wiki/Merge_sort 希尔排序https://en.wikipedia.org/wiki/Shellsort 计数排序https://en.wikipedia.org/wiki/Counting_sort 基数排序https://en.wikipedia.org/wiki/Radix_sort 桶排序https://en.wikipedia.org/wiki/Bucket_sort 堆排序https://en.wikipedia.org/wiki/Heapsort 代码实现所有的排序算法接口都是相同的，也就是 vector&lt;int&gt; xxxSort(vector&lt;int&gt;&amp; nums) 。只需要你传入一个 vector&lt;int&gt; 类型的数组，就能返回排序后的结果。 运行下来可以发现，桶排序速度是比较快的。而冒泡排序、选择排序和插入排序因为时间复杂度太高无法通过本题，基数排序因为无法处理负数也不能通过本题。 class Solution { public: vector&lt;int&gt; sortArray(vector&lt;int&gt;&amp; nums) { return quickSort(nums); } // 冒泡排序（超时） vector&lt;int&gt; bubbleSort(vector&lt;int&gt;&amp; nums) { int n = nums.size(); for (int i = 0; i &lt; n; ++i) { for (int j = n-2; j &gt;= i; --j) { if (nums[j] &gt; nums[j+1]) { swap(nums[j], nums[j+1]); } } } return nums; } // 选择排序（超时） vector&lt;int&gt; selectSort(vector&lt;int&gt;&amp; nums) { int n = nums.size(); for (int i = 0; i &lt; n; ++i) { int idx = i; for (int j = i; j &lt; n; ++j) { if (nums[j] &lt; nums[idx]) { idx = j; } } swap(nums[i], nums[idx]); } return nums; } // 插入排序（超时） vector&lt;int&gt; insertSort(vector&lt;int&gt;&amp; nums) { int n = nums.size(); for (int i = 0; i &lt; n; ++i) { for (int j = i; j &gt; 0 &amp;&amp; nums[j] &lt; nums[j-1]; --j) { swap(nums[j], nums[j-1]); } } return nums; } // 快速排序（24 ms） void qSort(vector&lt;int&gt;&amp; nums, int l, int r) { if (l &gt;= r) return; int m = l; for (int i = l; i &lt; r; ++i) { if (nums[i] &lt; nums[r]) { swap(nums[m++], nums[i]); } } swap(nums[m], nums[r]); qSort(nums, l, m-1); qSort(nums, m+1, r); } vector&lt;int&gt; quickSort(vector&lt;int&gt;&amp; nums) { int n = nums.size(); qSort(nums, 0, n-1); return nums; } // 归并排序（192 ms） vector&lt;int&gt; mSort(vector&lt;int&gt;&amp; nums, int l, int r) { if (l &gt;= r) return {nums[l]}; int m = l+(r-l)/2; vector&lt;int&gt; lnums = mSort(nums, l, m); vector&lt;int&gt; rnums = mSort(nums, m+1, r); vector&lt;int&gt; res; int i = 0, j = 0; while (i &lt;= m-l &amp;&amp; j &lt;= r-m-1) { if (lnums[i] &lt; rnums[j]) { res.push_back(lnums[i++]); } else { res.push_back(rnums[j++]); } } while (i &lt;= m-l) { res.push_back(lnums[i++]); } while (j &lt;= r-m-1) { res.push_back(rnums[j++]); } return res; } vector&lt;int&gt; mergeSort(vector&lt;int&gt;&amp; nums) { int n = nums.size(); nums = mSort(nums, 0, n-1); return nums; } // 归并排序 + 非递归（80 ms） vector&lt;int&gt; mergeSortNR(vector&lt;int&gt;&amp; nums) { int n = nums.size(); for (int len = 1; len &lt; n; len &lt;&lt;= 1) { for (int l = 0; l &lt; n-len; l += 2*len) { int m = l+len-1; int r = min(n-1, l+2*len-1); vector&lt;int&gt; res; int i = l, j = m+1; while (i &lt;= m &amp;&amp; j &lt;= r) { if (nums[i] &lt; nums[j]) { res.push_back(nums[i++]); } else { res.push_back(nums[j++]); } } while (i &lt;= m) { res.push_back(nums[i++]); } while (j &lt;= r) { res.push_back(nums[j++]); } for (int i = l; i &lt;= r; ++i) { nums[i] = res[i-l]; } } } return nums; } // 希尔排序（40 ms） vector&lt;int&gt; shellSort(vector&lt;int&gt;&amp; nums) { int n = nums.size(); for (int gap = n/2; gap &gt; 0; gap /= 2) { for (int i = gap; i &lt; n; ++i) { for (int j = i; j-gap &gt;= 0 &amp;&amp; nums[j-gap] &gt; nums[j]; j -= gap) { swap(nums[j-gap], nums[j]); } } } return nums; } // 计数排序（32 ms） vector&lt;int&gt; countSort(vector&lt;int&gt;&amp; nums) { int n = nums.size(); if (!n) return {}; int minv = *min_element(nums.begin(), nums.end()); int maxv = *max_element(nums.begin(), nums.end()); int m = maxv-minv+1; vector&lt;int&gt; count(m, 0); for (int i = 0; i &lt; n; ++i) { count[nums[i]-minv]++; } vector&lt;int&gt; res; for (int i = 0; i &lt; m; ++i) { for (int j = 0; j &lt; count[i]; ++j) { res.push_back(i+minv); } } return res; } // 基数排序（不适用于负数） vector&lt;int&gt; radixSort(vector&lt;int&gt;&amp; nums) { int n = nums.size(); int maxv = *max_element(nums.begin(), nums.end()); int maxd = 0; while (maxv &gt; 0) { maxv /= 10; maxd++; } vector&lt;int&gt; count(10, 0), rank(n, 0); int base = 1; while (maxd &gt; 0) { count.assign(10, 0); for (int i = 0; i &lt; n; ++i) { count[(nums[i]/base)%10]++; } for (int i = 1; i &lt; 10; ++i) { count[i] += count[i-1]; } for (int i = n-1; i &gt;= 0; --i) { rank[--count[(nums[i]/base)%10]] = nums[i]; } for (int i = 0; i &lt; n; ++i) { nums[i] = rank[i]; } maxd--; base *= 10; } return nums; } // 桶排序 (20 ms) vector&lt;int&gt; bucketSort(vector&lt;int&gt;&amp; nums) { int n = nums.size(); int maxv = *max_element(nums.begin(), nums.end()); int minv = *min_element(nums.begin(), nums.end()); int bs = 1000; int m = (maxv-minv)/bs+1; vector&lt;vector&lt;int&gt; &gt; bucket(m); for (int i = 0; i &lt; n; ++i) { bucket[(nums[i]-minv)/bs].push_back(nums[i]); } int idx = 0; for (int i = 0; i &lt; m; ++i) { int sz = bucket[i].size(); bucket[i] = quickSort(bucket[i]); for (int j = 0; j &lt; sz; ++j) { nums[idx++] = bucket[i][j]; } } return nums; } // 堆排序（32 ms） void adjust(vector&lt;int&gt;&amp; nums, int p, int s) { while (2*p+1 &lt; s) { int c1 = 2*p+1; int c2 = 2*p+2; int c = (c2&lt;s &amp;&amp; nums[c2]&gt;nums[c1]) ? c2 : c1; if (nums[c] &gt; nums[p]) swap(nums[c], nums[p]); else break; p = c; } } vector&lt;int&gt; heapSort(vector&lt;int&gt;&amp; nums) { int n = nums.size(); for (int i = n/2-1; i &gt;= 0; --i) { adjust(nums, i, n); } for (int i = n-1; i &gt; 0; --i) { swap(nums[0], nums[i]); adjust(nums, 0, i); } return nums; } };","categories":[{"name":"编程算法","slug":"编程算法","permalink":"http://he49816306.github.io/categories/%E7%BC%96%E7%A8%8B%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://he49816306.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://he49816306.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-02-15T07:09:23.000Z","updated":"2022-08-03T12:37:14.268Z","comments":true,"path":"2020/02/15/hello-world/","link":"","permalink":"http://he49816306.github.io/2020/02/15/hello-world/","excerpt":"","text":"Welcome to blog! This is your very first post. hello hello~","categories":[{"name":"编程算法","slug":"编程算法","permalink":"http://he49816306.github.io/categories/%E7%BC%96%E7%A8%8B%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://he49816306.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://he49816306.github.io/tags/%E7%AE%97%E6%B3%95/"}]}],"categories":[{"name":"技术原理","slug":"技术原理","permalink":"http://he49816306.github.io/categories/%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86/"},{"name":"并发操作","slug":"并发操作","permalink":"http://he49816306.github.io/categories/%E5%B9%B6%E5%8F%91%E6%93%8D%E4%BD%9C/"},{"name":"生活日常","slug":"生活日常","permalink":"http://he49816306.github.io/categories/%E7%94%9F%E6%B4%BB%E6%97%A5%E5%B8%B8/"},{"name":"编程算法","slug":"编程算法","permalink":"http://he49816306.github.io/categories/%E7%BC%96%E7%A8%8B%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"原理","slug":"原理","permalink":"http://he49816306.github.io/tags/%E5%8E%9F%E7%90%86/"},{"name":"监控","slug":"监控","permalink":"http://he49816306.github.io/tags/%E7%9B%91%E6%8E%A7/"},{"name":"思想","slug":"思想","permalink":"http://he49816306.github.io/tags/%E6%80%9D%E6%83%B3/"},{"name":"设计模式","slug":"设计模式","permalink":"http://he49816306.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"多线程","slug":"多线程","permalink":"http://he49816306.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"优化","slug":"优化","permalink":"http://he49816306.github.io/tags/%E4%BC%98%E5%8C%96/"},{"name":"并发","slug":"并发","permalink":"http://he49816306.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"源码","slug":"源码","permalink":"http://he49816306.github.io/tags/%E6%BA%90%E7%A0%81/"},{"name":"闲聊","slug":"闲聊","permalink":"http://he49816306.github.io/tags/%E9%97%B2%E8%81%8A/"},{"name":"leetcode","slug":"leetcode","permalink":"http://he49816306.github.io/tags/leetcode/"},{"name":"算法","slug":"算法","permalink":"http://he49816306.github.io/tags/%E7%AE%97%E6%B3%95/"}]}